# Logstash 9.x Pipeline Configuration
# This pipeline accepts GELF input and outputs to Elasticsearch

input {
  # GELF (Graylog Extended Log Format) input
  # Used by Docker GELF log driver
  gelf {
    port => 12201
    type => "docker"
  }

  # Uncomment to enable syslog input (non-privileged port)
  # syslog {
  #   port => 5514
  #   type => "syslog"
  # }
}

filter {
  # Replace dots in field names with underscores
  # This prevents mapping conflicts in Elasticsearch
  ruby {
    code => '
      def replace_dots(hash)
        hash.keys.each do |key|
          if key.include?(".")
            new_key = key.gsub(".", "_")
            hash[new_key] = hash.delete(key)
            key = new_key
          end
          if hash[key].is_a?(Hash)
            replace_dots(hash[key])
          end
        end
      end
      replace_dots(event.to_hash)
    '
  }

  # Add timestamp if not present
  if ![timestamp] {
    mutate {
      add_field => { "timestamp" => "%{@timestamp}" }
    }
  }

  # Parse Docker container info from GELF
  if [type] == "docker" {
    mutate {
      rename => { "host" => "docker_host" }
      rename => { "container_id" => "docker_container_id" }
      rename => { "container_name" => "docker_container_name" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOSTS:elasticsearch:9200}"]
    user => "${ELASTICSEARCH_USERNAME:elastic}"
    password => "${ELASTICSEARCH_PASSWORD:changeme}"
    # Index pattern: logstash-YYYY.MM.dd
    index => "logstash-%{+YYYY.MM.dd}"
    # Uncomment for SSL/TLS connections
    # ssl => true
    # cacert => "/etc/logstash/certs/ca.crt"
  }

  # Uncomment for debugging
  # stdout {
  #   codec => rubydebug
  # }
}

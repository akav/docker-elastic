# Elastic Stack 9.x Docker Swarm Deployment
# Optimized for Linux Docker Swarm

services:

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_VERSION:-9.2.4}
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      # Cluster configuration
      - node.name=es-{{.Task.Slot}}
      - cluster.name=DevOps
      - network.host=0.0.0.0
      # Discovery - use single-node for development, or set DISCOVERY_TYPE=multi-node for cluster
      - discovery.type=${DISCOVERY_TYPE:-single-node}
      # Security settings
      - ELASTIC_PASSWORD=${ELASTICSEARCH_PASSWORD:-changeme}
      - xpack.security.enabled=true
      - xpack.security.audit.enabled=true
      # Prevent accidental index deletion
      - action.destructive_requires_name=true
      # Memory settings - adjust based on available RAM
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
    networks:
      - elastic
    volumes:
      - elasticsearch:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -sf -u elastic:${ELASTICSEARCH_PASSWORD:-changeme} http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  logstash:
    image: docker.elastic.co/logstash/logstash:${ELASTIC_VERSION:-9.2.4}
    hostname: "{{.Node.Hostname}}-logstash"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=${ELASTICSEARCH_USERNAME:-elastic}
      - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD:-changeme}
      # Monitoring via Elastic Agent is recommended for 8.x+
      - MONITORING_ENABLED=false
      - "LS_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "12201:12201/udp"
    networks:
      - elastic
    configs:
      - source: ls_config
        target: /usr/share/logstash/pipeline/logstash.conf
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:9600 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Setup service - runs once to configure Elasticsearch users
  setup:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_VERSION:-9.2.4}
    user: "0"
    command: >
      bash -c '
        echo "Waiting for Elasticsearch to be ready..."
        until curl -sf -u elastic:${ELASTICSEARCH_PASSWORD:-changeme} http://elasticsearch:9200/_cluster/health; do
          sleep 5
        done
        echo "Setting kibana_system password..."
        curl -sf -X POST -u elastic:${ELASTICSEARCH_PASSWORD:-changeme} \
          -H "Content-Type: application/json" \
          http://elasticsearch:9200/_security/user/kibana_system/_password \
          -d "{\"password\":\"${KIBANA_SYSTEM_PASSWORD:-changeme}\"}"
        echo ""
        echo "Setup complete!"
      '
    networks:
      - elastic
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 5
      resources:
        limits:
          memory: 256M

  kibana:
    image: docker.elastic.co/kibana/kibana:${ELASTIC_VERSION:-9.2.4}
    hostname: kibana
    ports:
      - "5601:5601"
    environment:
      - SERVER_NAME=kibana
      - SERVER_HOST=0.0.0.0
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      # Must use kibana_system user, not elastic superuser (Elastic 8+ requirement)
      - ELASTICSEARCH_USERNAME=kibana_system
      - ELASTICSEARCH_PASSWORD=${KIBANA_SYSTEM_PASSWORD:-changeme}
      # Encryption key must be exactly 32 characters
      - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${KIBANA_ENCRYPTION_KEY:-aV67MfXdown18LNlA9Jt3kWuaC2xYz99}
      - XPACK_REPORTING_ENCRYPTIONKEY=${KIBANA_ENCRYPTION_KEY:-aV67MfXdown18LNlA9Jt3kWuaC2xYz99}
      - XPACK_SECURITY_ENCRYPTIONKEY=${KIBANA_ENCRYPTION_KEY:-aV67MfXdown18LNlA9Jt3kWuaC2xYz99}
      # Disable strict Content Security Policy for development
      - CSP_STRICT=false
    networks:
      - elastic
    volumes:
      - kibana:/usr/share/kibana/data
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 180s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

networks:
  elastic:
    driver: overlay
    attachable: true

volumes:
  elasticsearch:
  kibana:

configs:
  ls_config:
    file: ./elk/logstash/config/pipeline/logstash.conf
